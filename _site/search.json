[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Tidyverse",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MyLabJournal",
    "section": "",
    "text": "09— title: “My Lab Journal” subtitle: “Business Decisions with Machine Learning” author: “Arash Amiririgi”"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/01_Fundamentals.html",
    "href": "content/01_journal/01_Fundamentals.html",
    "title": "Machine Learning Fundamentals",
    "section": "",
    "text": "Challenge:\nYour organization wants to know which companies are similar to each other to help in identifying potential customers of a SAAS software solution (e.g. Sales force CRM or equivalent) in various segments of the market. The Sales Department is very interested in this analysis, which will help them more easily penetrate various market segments.\nCode:\n\nknitr::opts_chunk$set(\n    echo = TRUE,\n    message = FALSE,\n    warning = FALSE)\n\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(broom)\nlibrary(umap)\nsp_500_prices_tbl &lt;- read_rds(\"sp_500_prices_tbl.rds\")\nsp_500_prices_tbl\n\n\n\n  \n\n\nsp_500_index_tbl &lt;- read_rds(\"sp_500_index_tbl.rds\")\nsp_500_index_tbl\n\n\n\n  \n\n\n## Step 1 - Convert stock prices to a standardized format (daily returns)\nsp_500_daily_returns_tbl &lt;- sp_500_prices_tbl %&gt;% select(symbol,date, adjusted) %&gt;% filter(year(date) &gt;= '2018') %&gt;% group_by(symbol) %&gt;%\n  mutate(lag = lag(adjusted, n = 1)) %&gt;% filter(!(is.na(lag))) %&gt;% mutate(pct_return = (adjusted - lag)/lag) %&gt;%\n  select(symbol, date, pct_return)\nsp_500_daily_returns_tbl\n\n\n\n  \n\n\n## Step 2 - Convert to User-Item Format\nsp_500_daily_returns_tbl &lt;- read_rds(\"sp_500_daily_returns_tbl.rds\")\nsp_500_daily_returns_tbl\n\n\n\n  \n\n\nstock_date_matrix_tbl &lt;- sp_500_daily_returns_tbl %&gt;% pivot_wider(names_from = date, values_from = pct_return, values_fill = 0)\nstock_date_matrix_tbl\n\n\n\n  \n\n\n## Step 3 - Perform K-Means Clustering\nstock_date_matrix_tbl &lt;- read_rds(\"stock_date_matrix_tbl.rds\")\nkmeans_obj &lt;- stock_date_matrix_tbl %&gt;% select(-symbol) %&gt;% kmeans(centers = 4, nstart = 20)\n\n## Step 4 - Find the optimal value of K\nkmeans_mapper &lt;- function(center = 3) {\n    stock_date_matrix_tbl %&gt;%\n        select(-symbol) %&gt;%\n        kmeans(centers = center, nstart = 20)}\nk_means_mapped_tbl &lt;- tibble(centers = 1:30) %&gt;%\n    mutate(k_means = centers %&gt;% map(kmeans_mapper)) %&gt;%\n    mutate(glance  = k_means %&gt;% map(glance))\nk_means_mapped_tbl\n\n\n\n  \n\n\nk_means_mapped_tbl %&gt;% unnest(glance) %&gt;% select(centers, tot.withinss) %&gt;%  ggplot(aes(centers, tot.withinss)) +\n    geom_point(color = \"blue\", size = 4) +\n    geom_line(color = \"blue\", size = 1) +\n    ggrepel::geom_label_repel(aes(label = centers), color = \"blue\")\n\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n## Step 5 - Apply UMAP\nk_means_mapped_tbl &lt;- read_rds(\"k_means_mapped_tbl.rds\")\numap_results &lt;- stock_date_matrix_tbl %&gt;% select(-symbol) %&gt;% umap()\numap_results\n\n#&gt; umap embedding of 502 items in 2 dimensions\n#&gt; object components: layout, data, knn, config\n\numap_results_tbl &lt;- umap_results$layou %&gt;% as_tibble() %&gt;% set_names(c(\"x\", \"y\")) %&gt;% bind_cols(stock_date_matrix_tbl %&gt;% select(symbol))\n\n#&gt; Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n#&gt; `.name_repair` is omitted as of tibble 2.0.0.\n#&gt; ℹ Using compatibility `.name_repair`.\n\numap_results_tbl\n\n\n\n  \n\n\numap_results_tbl %&gt;% ggplot(aes(x, y)) + geom_point(alpha = 0.5) + theme_tq() + labs(title = \"UMAP Projection\")\n\n\n\n\n\n\n## Step 6 - Combine K-Means and UMAP\nk_means_mapped_tbl &lt;- read_rds(\"k_means_mapped_tbl.rds\")\numap_results_tbl   &lt;- read_rds(\"umap_results_tbl.rds\")\nk_means_obj &lt;- k_means_mapped_tbl %&gt;% pull(k_means) %&gt;% pluck(10)\numap_kmeans_results_tbl &lt;- k_means_obj %&gt;% augment(stock_date_matrix_tbl) %&gt;% select(symbol, .cluster) %&gt;% left_join(umap_results_tbl) %&gt;% left_join(sp_500_index_tbl %&gt;% select(symbol, company, sector))\n\n#&gt; Joining with `by = join_by(symbol)`\n\n\n#&gt; Joining with `by = join_by(symbol)`\n\numap_kmeans_results_tbl\n\n\n\n  \n\n\numap_kmeans_results_tbl %&gt;% ggplot(aes(V1, V2, color = .cluster)) + geom_point(alpha = 0.5)"
  },
  {
    "objectID": "content/01_journal/06_LIME.html",
    "href": "content/01_journal/06_LIME.html",
    "title": "Explaining Black-Box Models With LIME",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/05_Performance_Measures.html",
    "href": "content/01_journal/05_Performance_Measures.html",
    "title": "Performance Measures",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/04_H20_II.html",
    "href": "content/01_journal/04_H20_II.html",
    "title": "Automated Machine Learning with H20 (II)",
    "section": "",
    "text": "Challenge: The goal here is to predict whether or not a product will be put on backorder status, given a number of product metrics such as current inventory, transit time, demand forecasts and prior sales. It’s a classic Binary Classification problem.\nCode:\nLoading libraries\n\nlibrary(tidymodels)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(sjmisc)\nlibrary(magrittr)\nlibrary(haven)\nlibrary(sjlabelled)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(rstanarm)\nlibrary(broom.mixed)\nlibrary(h2o)\n\nLoading the training & test dataset\n\nproduct_backorders_tbl &lt;- read.csv(\"product_backorders.csv\")\nsplit_obj &lt;- initial_split(product_backorders_tbl, prop = 0.8)\ntrain_readable_tbl &lt;- training(split_obj)\ntest_readable_tbl  &lt;- testing(split_obj)\n\nSpecifying the response and predictor variables\nrunning AutoML specifying the stopping criterion\nView the leaderboard\nPredicting using Leader Model\nSave the leader model"
  },
  {
    "objectID": "content/01_journal/03_H20_I.html",
    "href": "content/01_journal/03_H20_I.html",
    "title": "Automated Machine Learning with H20 (I)",
    "section": "",
    "text": "Challenge: IBM has gathered information on employee satisfaction, income, seniority and some demographics. It includes the data of 1470 employees. In this regard, we are going to answer several questions based on the visualizations.\nCode:\n\n1 Business & Data Understanding: Department and Job Role\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(sjmisc)\nlibrary(magrittr)\nlibrary(haven)\nlibrary(sjlabelled)\nlibrary(stringr)\nemployee_attrition_tbl &lt;- read.csv(\"Employee_Attrition.csv\")\ndept_job_role_tbl &lt;- employee_attrition_tbl %&gt;%\n  select(EmployeeNumber, Department, JobRole, PerformanceRating, Attrition)\ndept_job_role_tbl %&gt;%\n  group_by(Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(pct = n / sum(n))\n\n\n\n  \n\n\n\n\n2 Attrition by department\n\ndept_job_role_tbl %&gt;%\n    group_by(Department, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department) %&gt;%\n  mutate(pct = n / sum(n))\n\n\n\n  \n\n\n\n\n3 Attrition by job role\n\ndept_job_role_tbl %&gt;%\n  group_by(Department, JobRole, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department, JobRole) %&gt;%\n  mutate(pct = n / sum(n)) %&gt;%\n  ungroup() %&gt;%\n  filter(Attrition %in% \"Yes\")\n\n\n\n  \n\n\n\n\n4 Develop KPI\n\ndept_job_role_tbl %&gt;%\n  group_by(Department, JobRole, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department, JobRole) %&gt;%\n  mutate(pct = n / sum(n)) %&gt;%\n  ungroup() %&gt;%\n  filter(Attrition %in% \"Yes\") %&gt;%\n  arrange(desc(pct)) %&gt;%\n  mutate(\n    above_industry_avg = case_when(\n      pct &gt; 0.088 ~ \"Yes\",\n      TRUE ~ \"No\"))\n\n\n\n  \n\n\n\n\n5 Function to calculate attrition cost\n\ncalculate_attrition_cost &lt;- function(\n  # Employee\n  n                    = 1,\n  salary               = 80000,\n  # Direct Costs\n  separation_cost      = 500,\n  vacancy_cost         = 10000,\n  acquisition_cost     = 4900,\n  placement_cost       = 3500,\n  # Productivity Costs\n  net_revenue_per_employee = 250000,\n  workdays_per_year        = 240,\n  workdays_position_open   = 40,\n  workdays_onboarding      = 60,\n  onboarding_efficiency    = 0.50) {\n  # Direct Costs\n  direct_cost &lt;- sum(separation_cost, vacancy_cost, acquisition_cost, placement_cost)\n  # Lost Productivity Costs\n  productivity_cost &lt;- net_revenue_per_employee / workdays_per_year *\n    (workdays_position_open + workdays_onboarding * onboarding_efficiency)\n  # Savings of Salary & Benefits (Cost Reduction)\n  salary_benefit_reduction &lt;- salary / workdays_per_year * workdays_position_open\n  # Estimated Turnover Per Employee\n  cost_per_employee &lt;- direct_cost + productivity_cost - salary_benefit_reduction\n  # Total Cost of Employee Turnover\n  total_cost &lt;- n * cost_per_employee\n  return(total_cost)}\n\n\n6 Function to convert counts to percentages.\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition)\n\n\n\n  \n\n\ncount_to_pct &lt;- function(data, ..., col = n) {\n  grouping_vars_expr &lt;- quos(...)\n  col_expr &lt;- enquo(col)\n  ret &lt;- data %&gt;%\n    group_by(!!! grouping_vars_expr) %&gt;%\n    mutate(pct = (!! col_expr) / sum(!! col_expr)) %&gt;%\n    ungroup()\n  return(ret)}\ndept_job_role_tbl %&gt;%\n  count(JobRole, Attrition) %&gt;%\n  count_to_pct(JobRole)\n\n\n\n  \n\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition) %&gt;%\n  count_to_pct(Department, JobRole) \n\n\n\n  \n\n\n\n\n7 Assess Attrition Function\n\nassess_attrition &lt;- function(data, attrition_col, attrition_value, baseline_pct) {\n  attrition_col_expr &lt;- enquo(attrition_col)\n  data %&gt;%\n    filter((!! attrition_col_expr) %in% attrition_value) %&gt;%\n    arrange(desc(pct)) %&gt;%\n    mutate(above_industry_avg = case_when(\n        pct &gt; baseline_pct ~ \"Yes\",\n        TRUE ~ \"No\"))}\n\n\n8 Visualization\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition) %&gt;%\n  count_to_pct(Department, JobRole) %&gt;%\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %&gt;%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)) %&gt;%\n  mutate(name = str_c(Department, JobRole, sep = \": \") %&gt;% as_factor()) %&gt;%\n  mutate(name      = fct_reorder(name, cost_of_attrition)) %&gt;%\n  mutate(cost_text = str_c(\"$\", format(cost_of_attrition / 1e6, digits = 2),\n                           \"M\", sep = \"\")) %&gt;%\n  ggplot(aes(cost_of_attrition, y = name)) +\n  geom_segment(aes(xend = 0, yend = name),    color = \"#2dc6d6\") +\n  geom_point(  aes(size = cost_of_attrition), color = \"#2dc6d6\") +\n  scale_x_continuous(labels = scales::dollar) +\n  geom_label(aes(label = cost_text, size = cost_of_attrition),\n             hjust = \"inward\", color = \"#2dc6d6\") +\n  scale_size(range = c(3, 5)) +\n  labs(title = \"Estimated cost of Attrition: By Dept and Job Role\",\n       y = \"\", x = \"Cost of attrition\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n# Descriptive Features\nemployee_attrition_tbl %&gt;% select(Age, DistanceFromHome, Gender, MaritalStatus, NumCompaniesWorked, Over18)\n\n\n\n  \n\n\n\n\n# Employment Features\nemployee_attrition_tbl %&gt;% select(Department, EmployeeCount, EmployeeNumber, JobInvolvement, JobLevel, JobRole, JobSatisfaction)\n\n\n\n  \n\n\n\n\n# Compensation Features\nemployee_attrition_tbl %&gt;% select(DailyRate, HourlyRate, MonthlyIncome, MonthlyRate, PercentSalaryHike, StockOptionLevel)\n\n\n\n  \n\n\n\n\n# Survery Results\nemployee_attrition_tbl %&gt;% select(EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction, WorkLifeBalance)\n\n\n\n  \n\n\n\n\n# Performance Data\nemployee_attrition_tbl %&gt;% select(JobInvolvement, PerformanceRating)\n\n\n\n  \n\n\n\n\n# Work-Life Features\nemployee_attrition_tbl %&gt;% select(BusinessTravel, OverTime)\n\n\n\n  \n\n\n\n\n# Training & Education\nemployee_attrition_tbl %&gt;% select(Education, EducationField, TrainingTimesLastYear)\n\n\n\n  \n\n\n\n\n# Time-Based Features\nemployee_attrition_tbl %&gt;% select(TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager)\n\n\n\n  \n\n\n\n\nlibrary(GGally)\nemployee_attrition_tbl %&gt;%\n  select(Attrition,  Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %&gt;%\n  ggpairs()\n\n\n\n\n\n\n\n\n9 Explore Features by Category\n\nplot_ggpairs &lt;- function(data, color = NULL, density_alpha = 0.5) {\n  color_expr &lt;- enquo(color)\n  if (rlang::quo_is_null(color_expr)) {\n    g &lt;- data %&gt;%\n      ggpairs(lower = \"blank\") \n    } else {\n    color_name &lt;- quo_name(color_expr)\n    g &lt;- data %&gt;%\n      ggpairs(mapping = aes_string(color = color_name), \n              lower = \"blank\", legend = 1,\n              diag = list(continuous = wrap(\"densityDiag\", \n                                            alpha = density_alpha))) +\n      theme(legend.position = \"bottom\")}\n  return(g)}\n\n\n10 Challanges\nDescriptive features: age, gender, marital status\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nEmployment features: department, job role, job level\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"employee\"), contains(\"department\"), contains(\"job\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nCompensation features: HourlyRate, MonthlyIncome, StockOptionLevel\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"income\"), contains(\"rate\"), contains(\"salary\"), contains(\"stock\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 1: What can you deduce about the interaction between Monthly Income and Attrition?\nAnswer: Those that are leaving have a lower Monthly Income\nQuestion 2:What can you deduce about the interaction between Percent Salary Hike and Attrition?\nAnswer: It’s difficult to deduce anything based on the visualization\nQuestion 3:What can you deduce about the interaction between Stock Option Level and Attrition?\nAnswer: Those that are staying have a higher stock option level\nSurvey Results: Satisfaction level, Work Life Balance\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"satisfaction\"), contains(\"life\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 4: What can you deduce about the interaction between Environment Satisfaction and Attrition?\nAnswer: A higher proportion of those leaving have a low environment satisfaction level\nQuestion 5:What can you deduce about the interaction between Work Life Balance and Attrition.\nAnswer: Those that are staying have a higher density of 2’s and 3’s\nPerformance Data: Job Involvement, Performance Rating\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"performance\"), contains(\"involvement\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 6: What Can you deduce about the interaction between Job Involvement and Attrition?\nAnswer: Those that are leaving have a lower density of 3’s and 4’s\nWork-Life Features\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"overtime\"), contains(\"travel\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 7: What can you deduce about the interaction between Over Time and Attrition?\nAnswer: The proportion of those staying that are working Over Time are high compared to those that are not staying\nTraining and Education\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"training\"), contains(\"education\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 8: What can you deduce about the interaction between Training Times Last Year and Attrition.\nAnswer: People that leave tend to have less annual training\nTime-Based Features: Years at company, years in current role\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"years\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 9: What can you deduce about the interaction between Years At Company and Attrition.\nAnswer: People that leave tend to have less working years at the company\nQuestion 10: What can you deduce about the interaction between Years Since Last Promotion and Attrition?\nAnswer: It’s difficult to deduce anything based on the visualization"
  },
  {
    "objectID": "content/01_journal/02_Regression.html",
    "href": "content/01_journal/02_Regression.html",
    "title": "Supervised ML - Regression",
    "section": "",
    "text": "Challenge: Our goal is to figure out what gaps exist in the products and come up with a pricing algorithm that will help us to determine a price, if we were to come up with products in that product cateogry.\nCode:\n\n# load libraries\nlibrary(tidyverse)\nlibrary(parsnip)\nlibrary(tidymodels)\nlibrary(rstanarm)\nlibrary(broom.mixed)\nlibrary(recipes)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(rpart.plot)\n\n\n# Build the model\nknitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)\noptions(dplyr.summarise.inform = FALSE)\noptions(warn=-1)\nbike_orderlines_tbl &lt;- readRDS(\"bike_orderlines.rds\")\nmodel_sales_tbl &lt;- bike_orderlines_tbl %&gt;%\n  select(total_price, model, category_2, frame_material) %&gt;%\n  group_by(model, category_2, frame_material) %&gt;%\n  summarise(total_sales = sum(total_price)) %&gt;%\n  ungroup() %&gt;% arrange(desc(total_sales))\nmodel_sales_tbl %&gt;% mutate(category_2 = as_factor(category_2) %&gt;% \n                             fct_reorder(total_sales, .fun = max) %&gt;% \n                             fct_rev()) %&gt;%\n  ggplot(aes(frame_material, total_sales)) +\n  geom_violin() +\n  geom_jitter(width = 0.1, alpha = 0.5, color = \"#2c3e50\") +\n  facet_wrap(~ category_2) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, suffix = \"M\", accuracy = 0.1)) +\n  tidyquant::theme_tq() +\n  labs(title = \"Total Sales for Each Model\",x = \"Frame Material\", y = \"Revenue\")\n\n#&gt; Registered S3 method overwritten by 'quantmod':\n#&gt;   method            from\n#&gt;   as.zoo.data.frame zoo\n\n\n\n\n\n\n\nbike_features_tbl &lt;- readRDS(\"bike_features_tbl.rds\")\nbike_features_tbl &lt;- bike_features_tbl %&gt;% \n  select(frame_material:gender, `Rear Derailleur`, `Shift Lever`) %&gt;% \n  mutate(`shimano dura-ace`        = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano dura-ace \") %&gt;% as.numeric(),\n         `shimano ultegra`         = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano ultegra \") %&gt;% as.numeric(),\n         `shimano 105`             = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano 105 \") %&gt;% as.numeric(),\n         `shimano tiagra`          = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano tiagra \") %&gt;% as.numeric(),\n         `Shimano sora`            = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano sora\") %&gt;% as.numeric(),\n         `shimano deore`           = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano deore(?! xt)\") %&gt;% as.numeric(),\n         `shimano slx`             = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano slx\") %&gt;% as.numeric(),\n         `shimano grx`             = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano grx\") %&gt;% as.numeric(),\n         `Shimano xt`              = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano deore xt |shimano xt \") %&gt;% as.numeric(),\n         `Shimano xtr`             = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano xtr\") %&gt;% as.numeric(),\n         `Shimano saint`           = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"shimano saint\") %&gt;% as.numeric(),\n         `SRAM red`                = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram red\") %&gt;% as.numeric(),\n         `SRAM force`              = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram force\") %&gt;% as.numeric(),\n         `SRAM rival`              = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram rival\") %&gt;% as.numeric(),\n         `SRAM apex`               = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram apex\") %&gt;% as.numeric(),\n         `SRAM xx1`                = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram xx1\") %&gt;% as.numeric(),\n         `SRAM x01`                = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram x01|sram xo1\") %&gt;% as.numeric(),\n         `SRAM gx`                 = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram gx\") %&gt;% as.numeric(),\n         `SRAM nx`                 = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram nx\") %&gt;% as.numeric(),\n         `SRAM sx`                 = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram sx\") %&gt;% as.numeric(),\n         `SRAM sx`                 = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"sram sx\") %&gt;% as.numeric(),\n         `Campagnolo potenza`      = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"campagnolo potenza\") %&gt;% as.numeric(),\n         `Campagnolo super record` = `Rear Derailleur` %&gt;% str_to_lower() %&gt;% str_detect(\"campagnolo super record\") %&gt;% as.numeric(),\n         `shimano nexus`           = `Shift Lever`     %&gt;% str_to_lower() %&gt;% str_detect(\"shimano nexus\") %&gt;% as.numeric(),\n         `shimano alfine`          = `Shift Lever`     %&gt;% str_to_lower() %&gt;% str_detect(\"shimano alfine\") %&gt;% as.numeric()) %&gt;%  \n  select(-c(`Rear Derailleur`, `Shift Lever`)) %&gt;% \n  mutate_if(is.numeric, ~replace(., is.na(.), 0)) \n\nbike_features_tbl &lt;- bike_features_tbl %&gt;% \n  mutate(id = row_number()) %&gt;% \n  mutate(frame_material = factor(frame_material)) %&gt;%\n  select(id, everything()) \n\nbike_features_tbl %&gt;% distinct(category_2)\n\n\n\n  \n\n\nsplit_obj &lt;- initial_split(bike_features_tbl, prop   = 0.80, strata = \"category_2\")\nsplit_obj %&gt;% training() %&gt;% distinct(category_2)\n\n\n\n  \n\n\nsplit_obj %&gt;% testing() %&gt;% distinct(category_2)\n\n\n\n  \n\n\ntrain_tbl &lt;- training(split_obj)\ntest_tbl  &lt;- testing(split_obj)\ntrain_tbl &lt;- train_tbl %&gt;% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  &lt;- test_tbl  %&gt;% set_names(str_replace_all(names(test_tbl), \" |-\", \"_\"))\n\n\n# Create features with the recipes package\noptions(warn=-1)\nbike_rec &lt;- recipe(frame_material ~ ., data = train_tbl) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;% \n  step_zv(all_predictors()) \n\n\n# Bundle the model and recipe with the workflow package\noptions(warn=-1)\nlr_mod &lt;- logistic_reg() %&gt;% set_engine(\"glm\")\nbike_wflow &lt;- workflow() %&gt;%add_model(lr_mod) %&gt;% add_recipe(bike_rec)\nbike_fit &lt;- bike_wflow %&gt;% fit(data = train_tbl)\nbike_fit %&gt;% pull_workflow_fit() %&gt;% tidy()\n\n\n\n  \n\n\nbike_predict &lt;- predict(bike_fit, test_tbl, type=\"prob\") %&gt;% \n  bind_cols(test_tbl %&gt;% select(frame_material, category_2)) \nbike_predict %&gt;% roc_curve(truth = frame_material, .pred_aluminium) %&gt;% \n  autoplot()\n\n\n\n\n\n\nbike_predict %&gt;% \n  roc_curve(truth = frame_material, .pred_carbon) %&gt;% \n  autoplot()\n\n\n\n\n\n\nbike_predict\n\n\n\n  \n\n\nbike_predict %&gt;% roc_auc(truth = frame_material, .pred_aluminium)\n\n\n\n  \n\n\nroc_car &lt;- bike_predict %&gt;% roc_auc(truth = frame_material, .pred_carbon)\n\n\n# Evaluate your model with the yardstick package\noptions(warn=-1)\nmodel_01_linear_lm_simple &lt;- linear_reg(mode = \"regression\") %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ category_2 + frame_material, data = train_tbl)\nmodel_01_linear_lm_simple\n\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = price ~ category_2 + frame_material, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;              (Intercept)        category_2All-Road            category_2City  \n#&gt;                  2064.64                    -70.69                  -1123.87  \n#&gt;  category_2Cross-Country      category_2Cyclocross       category_2Dirt Jump  \n#&gt;                   422.78                   -319.38                   -798.97  \n#&gt;       category_2Downhill          category_2E-City       category_2E-Fitness  \n#&gt;                  2282.18                   1004.79                    977.70  \n#&gt;       category_2E-Gravel      category_2E-Mountain          category_2E-Road  \n#&gt;                  1696.67                   1316.48                    854.36  \n#&gt;     category_2E-Trekking       category_2Endurance          category_2Enduro  \n#&gt;                  1260.08                   -469.88                    630.39  \n#&gt;      category_2Fat Bikes            category_2Race         category_2Touring  \n#&gt;                  -970.00                   1096.92                   -851.35  \n#&gt;          category_2Trail  category_2Triathlon Bike      frame_materialcarbon  \n#&gt;                  -177.79                    702.31                   1534.36\n\ntest_tbl &lt;- test_tbl %&gt;% filter(category_2 != \"Fat Bikes\")\n\nmodel_01_linear_lm_simple %&gt;%\n  predict(new_data = test_tbl) %&gt;%\n  bind_cols(test_tbl %&gt;% select(price)) %&gt;%\n  metrics(truth = price, estimate = .pred)\n\n\n\n  \n\n\ng1 &lt;- bike_features_tbl %&gt;% \n  mutate(category_2 = as.factor(category_2) %&gt;% \n           fct_reorder(price)) %&gt;% \n  ggplot(aes(category_2, price)) +\n  geom_violin() +\n  geom_jitter(width = 0.1, alpha = 0.5, color = \"#2dc6d6\") +\n  coord_flip() +\n  facet_wrap(~ frame_material) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs( title = \"Unit Price for Each Model\", y = \"\", x = \"Category 2\")\ng1\n\n\n\n\n\n\nnew_trail &lt;- tibble(\n  model = \"Exceed AL SL new\",\n  category_2 = \"Trail\",\n  frame_material = \"aluminium\",\n  shimano_dura_ace = 0,\n  shimano_ultegra = 0,\n  shimano_105 = 0,\n  shimano_tiagra = 0,\n  Shimano_sora = 0,\n  shimano_deore = 0,\n  shimano_slx = 0,\n  shimano_grx = 0,\n  Shimano_xt = 1,\n  Shimano_xtr = 0,\n  Shimano_saint = 0,\n  SRAM_red = 0,\n  SRAM_force = 0,\n  SRAM_rival = 0,\n  SRAM_apex = 0,\n  SRAM_xx1 = 0,\n  SRAM_x01 = 0,\n  SRAM_gx = 0,\n  SRAM_nx = 0,\n  SRAM_sx = 0,\n  Campagnolo_potenza = 0,\n  Campagnolo_super_record = 0,\n  shimano_nexus = 0,\n  shimano_alfine = 0)\nnew_trail\n\n\n\n  \n\n\npredict(model_01_linear_lm_simple, new_data = new_trail)\n\n\n\n  \n\n\nmodels_tbl &lt;- tibble(\n  model_id = str_c(\"Model 0\", 1:1),\n  model = list(\n    model_01_linear_lm_simple))\n\nmodels_tbl\n\n\n\n  \n\n\npredictions_new_trail_tbl &lt;- models_tbl %&gt;%\n  mutate(predictions = map(model, predict, new_data = new_trail)) %&gt;%\n  unnest(predictions) %&gt;%\n  mutate(category_2 = \"Trail\") %&gt;%\n  left_join(new_trail, by = \"category_2\")\npredictions_new_trail_tbl\n\n\n\n  \n\n\ng2 &lt;- g1 +\n  geom_point(aes(y = .pred), color = \"red\", alpha = 0.5,\n             data = predictions_new_trail_tbl) +\n  ggrepel::geom_text_repel(aes(label = model_id, y = .pred),\n                           size = 5,\n                           data = predictions_new_trail_tbl)\ng2"
  },
  {
    "objectID": "content/01_journal/03_H2O_I.html",
    "href": "content/01_journal/03_H2O_I.html",
    "title": "Automated Machine Learning with H20 (I)",
    "section": "",
    "text": "Challenge: IBM has gathered information on employee satisfaction, income, seniority and some demographics. It includes the data of 1470 employees. In this regard, we are going to answer several questions based on the visualizations.\nCode:\n\n1 Business & Data Understanding: Department and Job Role\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(sjmisc)\nlibrary(magrittr)\nlibrary(haven)\nlibrary(sjlabelled)\nlibrary(stringr)\nemployee_attrition_tbl &lt;- read.csv(\"Employee_Attrition.csv\")\ndept_job_role_tbl &lt;- employee_attrition_tbl %&gt;%\n  select(EmployeeNumber, Department, JobRole, PerformanceRating, Attrition)\ndept_job_role_tbl %&gt;%\n  group_by(Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(pct = n / sum(n))\n\n\n\n  \n\n\n\n\n2 Attrition by department\n\ndept_job_role_tbl %&gt;%\n    group_by(Department, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department) %&gt;%\n  mutate(pct = n / sum(n))\n\n\n\n  \n\n\n\n\n3 Attrition by job role\n\ndept_job_role_tbl %&gt;%\n  group_by(Department, JobRole, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department, JobRole) %&gt;%\n  mutate(pct = n / sum(n)) %&gt;%\n  ungroup() %&gt;%\n  filter(Attrition %in% \"Yes\")\n\n\n\n  \n\n\n\n\n4 Develop KPI\n\ndept_job_role_tbl %&gt;%\n  group_by(Department, JobRole, Attrition) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(Department, JobRole) %&gt;%\n  mutate(pct = n / sum(n)) %&gt;%\n  ungroup() %&gt;%\n  filter(Attrition %in% \"Yes\") %&gt;%\n  arrange(desc(pct)) %&gt;%\n  mutate(\n    above_industry_avg = case_when(\n      pct &gt; 0.088 ~ \"Yes\",\n      TRUE ~ \"No\"))\n\n\n\n  \n\n\n\n\n5 Function to calculate attrition cost\n\ncalculate_attrition_cost &lt;- function(\n  # Employee\n  n                    = 1,\n  salary               = 80000,\n  # Direct Costs\n  separation_cost      = 500,\n  vacancy_cost         = 10000,\n  acquisition_cost     = 4900,\n  placement_cost       = 3500,\n  # Productivity Costs\n  net_revenue_per_employee = 250000,\n  workdays_per_year        = 240,\n  workdays_position_open   = 40,\n  workdays_onboarding      = 60,\n  onboarding_efficiency    = 0.50) {\n  # Direct Costs\n  direct_cost &lt;- sum(separation_cost, vacancy_cost, acquisition_cost, placement_cost)\n  # Lost Productivity Costs\n  productivity_cost &lt;- net_revenue_per_employee / workdays_per_year *\n    (workdays_position_open + workdays_onboarding * onboarding_efficiency)\n  # Savings of Salary & Benefits (Cost Reduction)\n  salary_benefit_reduction &lt;- salary / workdays_per_year * workdays_position_open\n  # Estimated Turnover Per Employee\n  cost_per_employee &lt;- direct_cost + productivity_cost - salary_benefit_reduction\n  # Total Cost of Employee Turnover\n  total_cost &lt;- n * cost_per_employee\n  return(total_cost)}\n\n\n6 Function to convert counts to percentages.\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition)\n\n\n\n  \n\n\ncount_to_pct &lt;- function(data, ..., col = n) {\n  grouping_vars_expr &lt;- quos(...)\n  col_expr &lt;- enquo(col)\n  ret &lt;- data %&gt;%\n    group_by(!!! grouping_vars_expr) %&gt;%\n    mutate(pct = (!! col_expr) / sum(!! col_expr)) %&gt;%\n    ungroup()\n  return(ret)}\ndept_job_role_tbl %&gt;%\n  count(JobRole, Attrition) %&gt;%\n  count_to_pct(JobRole)\n\n\n\n  \n\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition) %&gt;%\n  count_to_pct(Department, JobRole) \n\n\n\n  \n\n\n\n\n7 Assess Attrition Function\n\nassess_attrition &lt;- function(data, attrition_col, attrition_value, baseline_pct) {\n  attrition_col_expr &lt;- enquo(attrition_col)\n  data %&gt;%\n    filter((!! attrition_col_expr) %in% attrition_value) %&gt;%\n    arrange(desc(pct)) %&gt;%\n    mutate(above_industry_avg = case_when(\n        pct &gt; baseline_pct ~ \"Yes\",\n        TRUE ~ \"No\"))}\n\n\n8 Visualization\n\ndept_job_role_tbl %&gt;%\n  count(Department, JobRole, Attrition) %&gt;%\n  count_to_pct(Department, JobRole) %&gt;%\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %&gt;%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)) %&gt;%\n  mutate(name = str_c(Department, JobRole, sep = \": \") %&gt;% as_factor()) %&gt;%\n  mutate(name      = fct_reorder(name, cost_of_attrition)) %&gt;%\n  mutate(cost_text = str_c(\"$\", format(cost_of_attrition / 1e6, digits = 2),\n                           \"M\", sep = \"\")) %&gt;%\n  ggplot(aes(cost_of_attrition, y = name)) +\n  geom_segment(aes(xend = 0, yend = name),    color = \"#2dc6d6\") +\n  geom_point(  aes(size = cost_of_attrition), color = \"#2dc6d6\") +\n  scale_x_continuous(labels = scales::dollar) +\n  geom_label(aes(label = cost_text, size = cost_of_attrition),\n             hjust = \"inward\", color = \"#2dc6d6\") +\n  scale_size(range = c(3, 5)) +\n  labs(title = \"Estimated cost of Attrition: By Dept and Job Role\",\n       y = \"\", x = \"Cost of attrition\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n# Descriptive Features\nemployee_attrition_tbl %&gt;% select(Age, DistanceFromHome, Gender, MaritalStatus, NumCompaniesWorked, Over18)\n\n\n\n  \n\n\n\n\n# Employment Features\nemployee_attrition_tbl %&gt;% select(Department, EmployeeCount, EmployeeNumber, JobInvolvement, JobLevel, JobRole, JobSatisfaction)\n\n\n\n  \n\n\n\n\n# Compensation Features\nemployee_attrition_tbl %&gt;% select(DailyRate, HourlyRate, MonthlyIncome, MonthlyRate, PercentSalaryHike, StockOptionLevel)\n\n\n\n  \n\n\n\n\n# Survery Results\nemployee_attrition_tbl %&gt;% select(EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction, WorkLifeBalance)\n\n\n\n  \n\n\n\n\n# Performance Data\nemployee_attrition_tbl %&gt;% select(JobInvolvement, PerformanceRating)\n\n\n\n  \n\n\n\n\n# Work-Life Features\nemployee_attrition_tbl %&gt;% select(BusinessTravel, OverTime)\n\n\n\n  \n\n\n\n\n# Training & Education\nemployee_attrition_tbl %&gt;% select(Education, EducationField, TrainingTimesLastYear)\n\n\n\n  \n\n\n\n\n# Time-Based Features\nemployee_attrition_tbl %&gt;% select(TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager)\n\n\n\n  \n\n\n\n\nlibrary(GGally)\nemployee_attrition_tbl %&gt;%\n  select(Attrition,  Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %&gt;%\n  ggpairs()\n\n\n\n\n\n\n\n\n9 Explore Features by Category\n\nplot_ggpairs &lt;- function(data, color = NULL, density_alpha = 0.5) {\n  color_expr &lt;- enquo(color)\n  if (rlang::quo_is_null(color_expr)) {\n    g &lt;- data %&gt;%\n      ggpairs(lower = \"blank\") \n    } else {\n    color_name &lt;- quo_name(color_expr)\n    g &lt;- data %&gt;%\n      ggpairs(mapping = aes_string(color = color_name), \n              lower = \"blank\", legend = 1,\n              diag = list(continuous = wrap(\"densityDiag\", \n                                            alpha = density_alpha))) +\n      theme(legend.position = \"bottom\")}\n  return(g)}\n\n\n10 Challanges\nDescriptive features: age, gender, marital status\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nEmployment features: department, job role, job level\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"employee\"), contains(\"department\"), contains(\"job\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nCompensation features: HourlyRate, MonthlyIncome, StockOptionLevel\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"income\"), contains(\"rate\"), contains(\"salary\"), contains(\"stock\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 1: What can you deduce about the interaction between Monthly Income and Attrition?\nAnswer: Those that are leaving have a lower Monthly Income\nQuestion 2:What can you deduce about the interaction between Percent Salary Hike and Attrition?\nAnswer: It’s difficult to deduce anything based on the visualization\nQuestion 3:What can you deduce about the interaction between Stock Option Level and Attrition?\nAnswer: Those that are staying have a higher stock option level\nSurvey Results: Satisfaction level, Work Life Balance\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"satisfaction\"), contains(\"life\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 4: What can you deduce about the interaction between Environment Satisfaction and Attrition?\nAnswer: A higher proportion of those leaving have a low environment satisfaction level\nQuestion 5:What can you deduce about the interaction between Work Life Balance and Attrition.\nAnswer: Those that are staying have a higher density of 2’s and 3’s\nPerformance Data: Job Involvement, Performance Rating\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"performance\"), contains(\"involvement\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 6: What Can you deduce about the interaction between Job Involvement and Attrition?\nAnswer: Those that are leaving have a lower density of 3’s and 4’s\nWork-Life Features\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"overtime\"), contains(\"travel\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 7: What can you deduce about the interaction between Over Time and Attrition?\nAnswer: The proportion of those staying that are working Over Time are high compared to those that are not staying\nTraining and Education\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"training\"), contains(\"education\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 8: What can you deduce about the interaction between Training Times Last Year and Attrition.\nAnswer: People that leave tend to have less annual training\nTime-Based Features: Years at company, years in current role\n\nemployee_attrition_tbl %&gt;%\n  select(Attrition, contains(\"years\")) %&gt;%\n  plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nQuestion 9: What can you deduce about the interaction between Years At Company and Attrition.\nAnswer: People that leave tend to have less working years at the company\nQuestion 10: What can you deduce about the interaction between Years Since Last Promotion and Attrition?\nAnswer: It’s difficult to deduce anything based on the visualization"
  }
]